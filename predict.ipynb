{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 \n",
    "import numpy as np \n",
    "import Neural_Networks as nn \n",
    "import Load_MNIST as lm\n",
    "import math\n",
    "import scipy.misc\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function extracts the opposite points of a rectangle.\n",
    "def getp(rect):\n",
    "    x = []; y=[];\n",
    "    for i in range(0,4):\n",
    "        x.append(rect[i][0][0])\n",
    "        y.append(rect[i][0][1])\n",
    "    x.sort()\n",
    "    y.sort()\n",
    "    return[[x[1],x[2]],[y[1],y[2]]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_image(im):\n",
    "    cv2.imshow('new',im)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All the images are have dimensions greater than 50x50\n",
    "def cropi(im):\n",
    "    try:\n",
    "        h,w = im.shape[:2]\n",
    "        roi = im[6:h-10, 10:w-15]\n",
    "        return roi\n",
    "    except:\n",
    "        return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function arranges the images in order from left to right and also gets the diagonal points \n",
    "def arrange(rects):\n",
    "\tar = [[[1001000]]]\n",
    "\tfor r in rects:\n",
    "\t\ttr = getp(r)\n",
    "\t\tprint tr\n",
    "\t\tfor i in range(0, len(ar)):\n",
    "\t\t\tif(tr[0][0] < ar[i][0][0]):\n",
    "\t\t\t\tar.insert(i,tr)\n",
    "\t\t\t\tbreak\n",
    "\treturn ar[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveimages(crops):\n",
    "    for i in range(1,len(crops)+1) :\n",
    "        print i\n",
    "        scipy.misc.imsave('outfile'+str(i)+'.jpg', crops[i-1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def savedata(crops):\n",
    "    os.chdir( cwd + '/outputs/data')\n",
    "    for i in range(0,len(crops)):\n",
    "        crops[i].dump(\"data\" + str(i+1) +\".data\")\n",
    "    os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function provides us with six nearly equal rectangles \n",
    "def filter(rects):\n",
    "\ttps = [[0]]\n",
    "\tfor r in rects:\n",
    "\t\tarea = cv2.contourArea(r)\n",
    "\t\tprint area\n",
    "\t\tx = True\n",
    "\t\tfor tp in tps:\n",
    "\t\t\tif(area > 0.8*tp[0] and area < 1.2*tp[0]):\n",
    "\t\t\t\ttp.append(r)\n",
    "\t\t\t\tx = False\n",
    "\t\tif(x):\n",
    "\t\t\ttps.append([area,r])\n",
    "\tfor tp in tps:\n",
    "\t\tif (len(tp) == 7 and tp[0] > 28*28):\n",
    "\t\t\treturn tp[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Setting to 650 by default change as required, lower than this won't be scaled.\n",
    "def initialize_image(file_name):\n",
    "    im = cv2.imread(file_name)\n",
    "    height,width = im.shape[:2]\n",
    "    # im = im[int(height*.25): int(height*0.75), int(width*.25):int(width*.75)]\n",
    "    print height;print width\n",
    "    rwidth = 400\n",
    "    sfactor = float(width)/rwidth\n",
    "    rheight = int(math.ceil(float(height)/sfactor ))\n",
    "    if(sfactor > 1):\n",
    "        return cv2.resize(im, (rwidth,rheight))\n",
    "    else:\n",
    "        return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_contours(rects):\n",
    "    for i in range(0,len(rects)) :\n",
    "        area = cv2.contourArea(rects[i])\n",
    "        cv2.drawContours(im,rects,i,(((i%2)+1)*255,(i%2)*255,0),2)\n",
    "        cv2.imshow('before',im)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reading all files from the folder and returning a list \n",
    "# get_list(1)\n",
    "\n",
    "def get_list(dir_no):\n",
    "    os.chdir('/home/mehak/Documents/HandwritingRecognitionANN/dataset/' )\n",
    "    list = os.listdir(str(dir_no))\n",
    "    return list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize(i):\n",
    "    a= np.zeros(10)\n",
    "    a[i] = 1\n",
    "    a = np.reshape(a,(10,1))\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_train_set():\n",
    "    training_set = []\n",
    "    for dir_no in range (0,10):\n",
    "        lis = get_list(dir_no)\n",
    "        t_data = process(dir_no, lis)\n",
    "        training_set += t_data\n",
    "        print len(lis)\n",
    "    return training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Process Images from a particular folder.\n",
    "#assuming present path to be at Handwriting Recoginition\n",
    "def process(dir_no, im_list):\n",
    "    os.chdir('/home/mehak/Documents/HandwritingRecognitionANN/dataset/' + str(dir_no) + '/')\n",
    "    print os.getcwd()\n",
    "    x = []\n",
    "    for im in im_list:\n",
    "        img = cv2.imread(im)\n",
    "        height,width = img.shape[:2]\n",
    "        rimg = cv2.resize(img, (28,28))\n",
    "        ret,rimg = cv2.threshold(rimg,127,255,cv2.THRESH_BINARY)\n",
    "        rimg = cv2.GaussianBlur(rimg,(1,1),0) \n",
    "        rimg = cv2.cvtColor( rimg, cv2.COLOR_RGB2GRAY )\n",
    "        dip = 255 - rimg\n",
    "        dip = cv2.dilate(dip, np.ones((2,2)))\n",
    "        dip = dip.astype(np.float32, copy=False)\n",
    "        dip = dip/255\n",
    "        dip = np.reshape(dip, (784,1))\n",
    "        x.append((dip,vectorize(dir_no)))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-68c5af9c179e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#The scaling factor is such that width will be 1000 else lesser for low pixel image.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-48ad92db2495>\u001b[0m in \u001b[0;36minitialize_image\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minitialize_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# im = im[int(height*.25): int(height*0.75), int(width*.25):int(width*.75)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;32mprint\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "#Saves the dimens of image, I wish to resize the image proportional to its original dimensions.\n",
    "#The scaling factor is such that width will be 1000 else lesser for low pixel image.\n",
    "file_name = sys.argv[1]\n",
    "im = initialize_image(file_name)\n",
    "height,width = im.shape[:2]\n",
    "print height \n",
    "print width\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'im' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-9cf3c5c99d31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfastNlMeansDenoising\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Thresholding requires a grayscale image 2nd param : threshvalue and 3rd param : maxValue of a pixel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mthresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCanny\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Closing is dialation followed by erosion helps to fill out the gaps left out by creases in paper or disconnected components.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'im' is not defined"
     ]
    }
   ],
   "source": [
    "imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "imgray = cv2.fastNlMeansDenoising(imgray,None,10,7,21)\n",
    "#Thresholding requires a grayscale image 2nd param : threshvalue and 3rd param : maxValue of a pixel\n",
    "thresh = cv2.Canny(imgray, 60, 200)\n",
    "#Closing is dialation followed by erosion helps to fill out the gaps left out by creases in paper or disconnected components.\n",
    "#Size of kernel is area of sliding window, I think it should be proportional to the size of image/boxes we will be using.\n",
    "ki = int(math.ceil(float(width)/100))\n",
    "kernel = np.ones((ki,ki), np.uint8)\n",
    "print ki\n",
    "# kernel = np.ones((4,4), np.uint8)\n",
    "thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "#Countours are curves joining all the continuous points having same colour or intensity.\n",
    "#http://opencvpython.blogspot.in/2012/06/hi-this-article-is-tutorial-which-try.html\n",
    "#The result \"contours\" is a Python list, where it contains all objects boundary points as separate lists.\n",
    "#Whichever element of contoeur is to be drawn set the 2nd param accordingly on an index of zero, -1 to show all the contours \n",
    "#Last arguement draws the boundary in pixels pass -1 for a filled image.\n",
    "thresh2=thresh.copy()\n",
    "im2, contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "#Contour Approximation to detect shapes.\n",
    "approx = []\n",
    "for i in range(0,len(contours)) :\n",
    "    epsilon = 0.025*cv2.arcLength (contours[i],True)\n",
    "    approx.append(cv2.approxPolyDP(contours[i],epsilon,True))\n",
    "\n",
    "#Separate the ones which are rectangles. :)\n",
    "rects = []\n",
    "for i in range(0,len(approx)):\n",
    "    if(len(approx[i]) == 4):\n",
    "        rects.append(approx[i])\n",
    "\n",
    "        \n",
    "if(len(rects) > 6):\n",
    "    rects = filter(rects)\n",
    "im = initialize_image(file_name)\n",
    "#Arrange in ascending order of x and put in opposite points \n",
    "frects = arrange(rects)\n",
    "#Ahead of this show_contours won't work as only opposite points are returned.\n",
    "im = initialize_image(file_name)\n",
    "crops = []\n",
    "for r in frects:\n",
    "    crops.append( im[ r[1][0]:r[1][1], r[0][0]:r[0][1] ] )\n",
    "# saveimages(crops)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "show_contours(rects) \n",
    "\n",
    "\n",
    "train_set = make_train_set()\n",
    "net = nn.Network([784,30,10])\n",
    "os.chdir('/home/mehak/Documents/HandwritingRecognitionANN/')\n",
    "net.load()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# np.shape(mnist.test.images)  Gives (10000, 784) \n",
    "# np.shape(mnist.test.labels) Gives (10000, 10)\n",
    "# print(sess.run(tf.argmax(y,1), feed_dict={x: mnist.test.images})) Gives [7 2 1 ..., 4 8 6]\n",
    "\"\"\"Give a proper Thresholding now.\"\"\"\n",
    "os.chdir('/home/mehak/Documents/HandwritingRecognitionANN/')\n",
    "def predict():\n",
    "    x = []\n",
    "    for crop in crops:\n",
    "        crop = cropi(crop)\n",
    "        rimg = cv2.resize(crop, (28,28))\n",
    "        ret,rimg = cv2.threshold(rimg,127,255,cv2.THRESH_BINARY)\n",
    "        rimg = cv2.GaussianBlur(rimg,(1,1),0) \n",
    "        rimg = cv2.cvtColor( rimg, cv2.COLOR_RGB2GRAY )\n",
    "        dip = 255 - rimg\n",
    "        dip = cv2.dilate(dip, np.ones((1,1)))\n",
    "        dip = dip.astype(np.float32, copy=False)\n",
    "        dip = dip/255\n",
    "        show_image(dip)\n",
    "        dip = np.reshape(dip, (784,1))\n",
    "        a=np.argmax(net.feedforward(dip))\n",
    "        print a\n",
    "        x.append(a)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pin = predict()\n",
    "print ''.join(str(x) for x in pin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
